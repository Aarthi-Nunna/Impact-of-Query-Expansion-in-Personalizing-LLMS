{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import drive to save index (if necessary)"
      ],
      "metadata": {
        "id": "bh94I2rtUDWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "CRyKQ46ltpck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If indexing is done, and stored in drive"
      ],
      "metadata": {
        "id": "57GNJ1TLVRNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l '/content/drive/MyDrive/646_Project/LaMP_2/index/'"
      ],
      "metadata": {
        "id": "H4SWYEi2KY6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required packages -\n",
        "1. pyterrier for indexing & retrieval\n",
        "2. transformers, torch, sentencepiece for flan-T5-base, accessing gpu\n",
        "3. dask for parallelization of index creation process using map_partitions"
      ],
      "metadata": {
        "id": "D3YD4FPIUmIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-terrier\n",
        "!pip install transformers[torch,sentencepiece]\n",
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "AaAiFtdmMWUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxeT3cPnYTxg"
      },
      "outputs": [],
      "source": [
        "import torch, os\n",
        "import dask.dataframe as dd\n",
        "import numpy as np, pandas as pd, pyterrier as pt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "if not pt.started():\n",
        "    pt.init(boot_packages = [\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():                 # Check if GPU is available\n",
        "    print(torch.cuda.get_device_name(0))      # Print GPU device name\n",
        "else:\n",
        "    print(\"GPU not available.\")"
      ],
      "metadata": {
        "id": "tOeTcACzuXQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load LaMP 2 data from source or google drive (if already saved)"
      ],
      "metadata": {
        "id": "iUvXH0kzUrUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('/content/drive/MyDrive/646_Project/train_questions.json')\n",
        "ddf = dd.from_pandas(df, npartitions = 4)"
      ],
      "metadata": {
        "id": "PCtILGj2QOOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddf['profile']"
      ],
      "metadata": {
        "id": "i7Zp3AuTRsHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PPEF and AIP functions for processing topK documents to create user personalized LLM inputs - These functions are defined in the appendix of LaMP paper"
      ],
      "metadata": {
        "id": "SmaNnx8nU6gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ppef(profile):\n",
        "        \"\"\" This function computes per profile entry prompt (PPEP) \"\"\"\n",
        "        text, category = profile['text'], profile['category']\n",
        "        return f'the category for the article: \"{text}\" is \"{category}\"'\n",
        "\n",
        "def aip(topk, inputQ):\n",
        "        \"\"\" This function computes aggregated input prompt (AIP) for the LLM \"\"\"\n",
        "        user_context = \", and \".join([ppef(doc) for doc in topk])\n",
        "        return user_context + f'. {inputQ}'"
      ],
      "metadata": {
        "id": "eCk38EmoorAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\n",
        "index_df = pd.util.testing.makeDataFrame\n",
        "user_profile_df = pd.util.testing.makeDataFrame"
      ],
      "metadata": {
        "id": "S6h04WLSL2NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for Index creation [user profiles] using pyterrier"
      ],
      "metadata": {
        "id": "4heXU6eGXCF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_index(x, task = 'LaMP_2', k=1):\n",
        "    user_profile_df = pd.DataFrame(x['profile'])\n",
        "    user_profile_df['context'] = user_profile_df[['title', 'text']].agg(' '.join, axis = 1)\n",
        "\n",
        "    df = user_profile_df[['id', 'context']].rename(columns = {'id': 'docno', 'context': 'text'})\n",
        "\n",
        "    path = f'/content/drive/MyDrive/646_Project/LaMP_2/index/index_{x[\"id\"]}'\n",
        "\n",
        "    if os.path.isdir(path):\n",
        "        # pyterrier creates 10 files in the index creation process\n",
        "        if len(os.listdir(path)) == 10:\n",
        "            return path\n",
        "\n",
        "    try:\n",
        "        # index the text, record the docnos as metadata\n",
        "        iter_indexer = pt.IterDictIndexer(path, overwrite = True)\n",
        "        indexref = iter_indexer.index(df.to_dict(orient = \"records\"))\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Creating index for {x['id']} with profile length of {df.shape[0]}\")\n",
        "        print(e)\n",
        "\n",
        "    return path"
      ],
      "metadata": {
        "id": "XTLOly5PR_li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def partition_func(dataframe):\n",
        "    return dataframe.apply(create_index, axis = 1)"
      ],
      "metadata": {
        "id": "MrqFdAQeRxIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Index - run index creation process"
      ],
      "metadata": {
        "id": "YLqHdDOaXE5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"Started indexing : \", df.shape[0])\n",
        "p = ddf.map_partitions(partition_func, meta = (None, 'str'))\n",
        "indexreferences = p.compute()\n",
        "print(\"Finished indexing : \", len(indexreferences), '\\n')"
      ],
      "metadata": {
        "id": "b6a72H5NyIM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(indexreferences[0])"
      ],
      "metadata": {
        "id": "4lrccfUguEy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexreferences"
      ],
      "metadata": {
        "id": "kOGOKKiSx-Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_expansion(x, indexref, k=4):\n",
        "    # define retriever pipeline (bm25, rm3) with default tokenizer for preprocessing query\n",
        "\n",
        "    profile, input = x['profile'], x['input']\n",
        "    _, query = input.split('] article: ')\n",
        "\n",
        "    user_profile_df = pd.DataFrame(profile)\n",
        "    user_profile_df['context'] = user_profile_df[['title', 'text']].agg(' '.join, axis = 1)\n",
        "    user_profile_df.rename(columns = {'id': 'docno'}, inplace = True)\n",
        "\n",
        "    bm25 = pt.BatchRetrieve(indexref, wmodel = 'BM25')\n",
        "    rm3 = pt.rewrite.RM3(indexref, fb_docs=10, fb_terms=10)\n",
        "\n",
        "    pipeline = pt.rewrite.tokenise() >> bm25 >> rm3 >> bm25\n",
        "\n",
        "    # topk documents for a user query\n",
        "    res = pipeline.search(input)\n",
        "    topK = res.head(k)\n",
        "    df = pd.merge(topK, user_profile_df, on = 'docno', how = 'inner')\n",
        "    prompt = aip(df.to_dict('records'), input)\n",
        "\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "TMPKMszyx_ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "prompts = []\n",
        "for row_1, (index_df2, row_df2) in  zip(indexreferences, ddf.iterrows()):\n",
        "  prompt = query_expansion(row_df2,row_1)\n",
        "  prompts.append(prompt)"
      ],
      "metadata": {
        "id": "NAUQY-tyT3tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompts[0], '\\n')"
      ],
      "metadata": {
        "id": "iULdxfWQNVaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load flan-t5-base model to CUDA"
      ],
      "metadata": {
        "id": "PcCF33qjXk0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"google/flan-t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "config = T5Config.from_pretrained(MODEL_NAME)\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, device_map=\"auto\")\n",
        "model.to('cuda')"
      ],
      "metadata": {
        "id": "BZLBMsU6tAzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to generate llm outputs"
      ],
      "metadata": {
        "id": "WILkpPDVXoeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llm_output(input_data):\n",
        "  input_ids = tokenizer(input_data, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "  outputs = model.generate(input_ids)\n",
        "  decoded_output = tokenizer.decode(outputs[0])\n",
        "  return decoded_output"
      ],
      "metadata": {
        "id": "0VddRjd5BZun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = pd.read_json('/content/drive/MyDrive/646_Project/train_outputs.json')"
      ],
      "metadata": {
        "id": "3k0P09FKuYLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truth_values = train_y['golds'].map(lambda x: x['output'])"
      ],
      "metadata": {
        "id": "DubbH5NUu8Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate LLM outputs"
      ],
      "metadata": {
        "id": "W9v_qTcoYETY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "outputs = []\n",
        "\n",
        "for prompt in prompts:\n",
        "  output = generate_llm_output(prompt)\n",
        "  outputs.append(output)\n",
        "\n",
        "print(\"Computed LLM Output \\n\")"
      ],
      "metadata": {
        "id": "yKZ68fWIk-qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process LLM output to extract category"
      ],
      "metadata": {
        "id": "V8v50_0yYASN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process(x):\n",
        "    try:\n",
        "        _, a = x.split('<pad>')\n",
        "        b, _ = a.split('</s>')\n",
        "        return b.strip('[|]| ').lower()\n",
        "    except:\n",
        "        print(x, '\\n')\n",
        "        return ''"
      ],
      "metadata": {
        "id": "sGmckx-2wg94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_outputs = []\n",
        "for x in outputs:\n",
        "  y = process(x)\n",
        "  processed_outputs.append(y)"
      ],
      "metadata": {
        "id": "oGi0cKwLwjQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processed Classification Labels - categories"
      ],
      "metadata": {
        "id": "DoiQD6v0X4mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(processed_outputs)"
      ],
      "metadata": {
        "id": "R4vheuSUAV9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute Accuracy, F1 scores"
      ],
      "metadata": {
        "id": "gOiCAJadX0-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(processed_outputs, truth_values.to_list(), average = \"macro\")\n",
        "acc = accuracy_score(processed_outputs, truth_values)\n",
        "\n",
        "print(f'F1 Score is: {f1}')\n",
        "print(f'Accuracy is: {acc}')"
      ],
      "metadata": {
        "id": "BGDNM8oCwZL1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}