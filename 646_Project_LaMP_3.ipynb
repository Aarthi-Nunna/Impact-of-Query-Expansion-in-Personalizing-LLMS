{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import drive to save index (if necessary)"
      ],
      "metadata": {
        "id": "VSd_G25NNoa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CRyKQ46ltpck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required packages -\n",
        "1. pyterrier for indexing & retrieval\n",
        "2. transformers, torch, sentencepiece for flan-T5-base, accessing gpu\n",
        "3. dask for parallelization of index creation process using map_partitions\n"
      ],
      "metadata": {
        "id": "1FiGZE4nNvTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-terrier\n",
        "!pip install transformers[torch,sentencepiece]\n",
        "!pip install torch torchvision\n",
        "# !pip install evaluate\n",
        "# !pip install rouge_score"
      ],
      "metadata": {
        "id": "AaAiFtdmMWUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxeT3cPnYTxg"
      },
      "outputs": [],
      "source": [
        "import dask.dataframe as dd, os, torch\n",
        "import numpy as np, pandas as pd, pyterrier as pt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# import nltk, evaluate\n",
        "# nltk.download(\"punkt\", quiet = True)\n",
        "\n",
        "if not pt.started():\n",
        "    pt.init(boot_packages = [\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():                 # Check if GPU is available\n",
        "    print(torch.cuda.get_device_name(0))      # Print GPU device name\n",
        "else:\n",
        "    print(\"GPU not available.\")"
      ],
      "metadata": {
        "id": "Bchk6yYtK-RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load LaMP_3 data from source"
      ],
      "metadata": {
        "id": "4tqfWchMOmr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder = 'train'\n",
        "df = pd.read_json(f'https://ciir.cs.umass.edu/downloads/LaMP/LaMP_3/{folder}/{folder}_questions.json')\n",
        "df.shape"
      ],
      "metadata": {
        "id": "PCtILGj2QOOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample 1500 after random shuffling for experiments and analysis"
      ],
      "metadata": {
        "id": "dLENo4DjOvNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac = 1, random_state = 42).head(1500)"
      ],
      "metadata": {
        "id": "JHxlDLUz-ozi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddf = dd.from_pandas(df, npartitions = 10)\n",
        "print(df.shape, '\\n')\n",
        "print(ddf)"
      ],
      "metadata": {
        "id": "btx-KAG66q-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for Index creation [user profiles] using pyterrier"
      ],
      "metadata": {
        "id": "4BMsd5C8O4ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_index(x):\n",
        "    user_profile_df = pd.DataFrame(x['profile'])\n",
        "    df = user_profile_df[['id', 'text']].rename(columns = {'id': 'docno'})\n",
        "\n",
        "    path = f'./lamp3/index_{x[\"id\"]}'\n",
        "\n",
        "    if os.path.isdir(path):\n",
        "        # pyterrier creates 10 files in the index creation process\n",
        "        if len(os.listdir(path)) == 10:\n",
        "            return path\n",
        "\n",
        "    try:\n",
        "        iter_indexer = pt.IterDictIndexer(path, overwrite=True)\n",
        "        indexref = iter_indexer.index(df.to_dict(orient = \"records\"))\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Creating index for {x['id']} with profile length of {df.shape[0]}\")\n",
        "        print(e)\n",
        "\n",
        "    return path"
      ],
      "metadata": {
        "id": "XTLOly5PR_li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def partition_func(dataframe):\n",
        "    return dataframe.apply(create_index, axis = 1)"
      ],
      "metadata": {
        "id": "MrqFdAQeRxIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run index creation process"
      ],
      "metadata": {
        "id": "HGqUDTryO_W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"Started indexing : \", df.shape[0])\n",
        "p = ddf.map_partitions(partition_func, meta = (None, 'str'))\n",
        "indexrefs = p.compute()\n",
        "print(\"Finished indexing : \", len(indexrefs), '\\n')"
      ],
      "metadata": {
        "id": "b6a72H5NyIM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PPEF and AIP functions for processing topK documents to create user personalized LLM inputs - These functions are defined in the appendix of LaMP paper"
      ],
      "metadata": {
        "id": "bmfSX4xHPHb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ppef(profile):\n",
        "    text, score = profile['text'], profile['score_y']\n",
        "    return f'{score} is the score for \"{text}\"'\n",
        "\n",
        "def aip(topk, inputQ):\n",
        "    user_context = \", and \".join([ppef(doc) for doc in topk])\n",
        "    return user_context + f'. {inputQ}'"
      ],
      "metadata": {
        "id": "4YaRzNLRFZ8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query Expansion Using BM25, &/or RM3 - Return User Personalized Prompt"
      ],
      "metadata": {
        "id": "czu6Pr1XPcHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def query_expansion(x, indexref, rtype, k = 1, args = [3, 10]):\n",
        "    # define retriever pipeline (bm25 and/or rm3) with default tokenizer for preprocessing user query\n",
        "\n",
        "    profile, input = x['profile'], x['input']\n",
        "    _, query = input.split('without further explanation. review: ')\n",
        "\n",
        "    user_profile_df = pd.DataFrame(profile)\n",
        "    user_profile_df = user_profile_df.rename(columns = {'id': 'docno'})\n",
        "\n",
        "    try:\n",
        "        pipeline = None\n",
        "        bm25 = pt.BatchRetrieve(indexref, wmodel = 'BM25')\n",
        "\n",
        "        if rtype == 'bm25':\n",
        "            pipeline = pt.rewrite.tokenise() >> bm25\n",
        "        else:\n",
        "            rm3 = pt.rewrite.RM3(indexref, fb_docs = args[0], fb_terms = args[1])\n",
        "            pipeline = pt.rewrite.tokenise() >> bm25 >> rm3 >> bm25\n",
        "\n",
        "        # retrieve topk\n",
        "        topK = pipeline.search(query).head(k)\n",
        "\n",
        "        # generate user profile personalized prompt\n",
        "        df = pd.merge(topK, user_profile_df, on = 'docno', how = 'inner')\n",
        "        prompt = aip(df.to_dict('records'), input)\n",
        "\n",
        "    except Exception as e:\n",
        "        prompt = aip([], input)\n",
        "        print('Error in retrieval for id: ', x['id'])\n",
        "        print(e)\n",
        "\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "UJMywp4lGHca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indexrefs from dask map_partitions can be a permutation of requried output. So, map 'id' to appropriate 'indexref'\n",
        "indexrefs = df['id'].map(lambda x: f'./lamp3/index_{str(x)}/')"
      ],
      "metadata": {
        "id": "PnbgeDA4Gkd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexrefs[:5]"
      ],
      "metadata": {
        "id": "XDPQ2j78G1vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Query Expansion and Generate User Personalized prompts for downstream LLM tasks - Predict Rating for product (LaMP 3)"
      ],
      "metadata": {
        "id": "_LuJFJxgPq1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "prompts, count = [], 0\n",
        "for row_1, (index_df2, row_df2) in  tqdm(zip(indexrefs, df.iterrows())):\n",
        "    prompt = query_expansion(row_df2, row_1, 'rm3', 4)\n",
        "    prompts.append(prompt)\n",
        "print('\\nNo of 0 retrieved results = ', count)"
      ],
      "metadata": {
        "id": "9HUrL28vG7Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts[5]"
      ],
      "metadata": {
        "id": "Qtc6mb_HIdz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Flan-T5-Base Model to CUDA"
      ],
      "metadata": {
        "id": "lhrLMNu9QZ9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"google/flan-t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, device_map = \"auto\")\n",
        "model.to('cuda')"
      ],
      "metadata": {
        "id": "pxt3LpygKUUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llm_output(input_data):\n",
        "    input_ids = tokenizer(input_data, return_tensors = \"pt\").input_ids.to(\"cuda\")\n",
        "    outputs = model.generate(input_ids)\n",
        "    decoded_output = tokenizer.decode(outputs[0])\n",
        "    return decoded_output"
      ],
      "metadata": {
        "id": "wWLfXghNKZ0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate LLM output"
      ],
      "metadata": {
        "id": "oDxK8IZlQff1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"[START] Compute LLM Output \\n\")\n",
        "outputs = []\n",
        "for prompt in prompts:\n",
        "  output = generate_llm_output(prompt)\n",
        "  outputs.append(output)\n",
        "  torch.cuda.empty_cache()\n",
        "print(\"[END]  Compute LLM Output \\n\")"
      ],
      "metadata": {
        "id": "RvhZxQ1eKh48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[:5]"
      ],
      "metadata": {
        "id": "Ay6cbktxLBf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save LLM Inputs & Output for further analysis"
      ],
      "metadata": {
        "id": "MCGF-QUhRdNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_output = pd.DataFrame({'id': list(indexrefs), 'prompts': prompts, 'llm_output': outputs})\n",
        "df_output.to_csv('output.csv')"
      ],
      "metadata": {
        "id": "-KQFVA4eKsqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df, df_output, prompts, outputs\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "i055VuBXQ58a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load output labels for training data"
      ],
      "metadata": {
        "id": "33p2-YBmQweY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('https://ciir.cs.umass.edu/downloads/LaMP/LaMP_3/train/train_outputs.json')\n",
        "df['id'] = df['golds'].map(lambda x: int(x['id']))\n",
        "df['target'] = df['golds'].map(lambda x: int(x['output']))\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "SdCsHouiQp54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute MAE, RMSE metrics for LaMP 3 dataset using 'output.csv' created above"
      ],
      "metadata": {
        "id": "5D-f0pYwRQtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "WWOOBiB3Rpks"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute(sett, df):\n",
        "    # Load output.csv files [multiple if ran in batches]\n",
        "    task = pd.concat([pd.read_csv(filename, usecols=['id', 'llm_output']) for filename in sett])\n",
        "\n",
        "    # extract id from indexref path\n",
        "    task['id'] = task['id'].map(lambda x: int(x.split('/')[-2].split('_')[1]))\n",
        "\n",
        "    # Filter label dataset including only relevant ids\n",
        "    pid_list = task['id'].tolist()\n",
        "    df_temp = df[df.id.isin(pid_list)]\n",
        "    ans = df_temp.merge(task, on = 'id', how = 'inner')\n",
        "\n",
        "    def process(x):\n",
        "        try:\n",
        "            return int(x.strip('<pad>').strip('</s>').strip().strip('-').strip())\n",
        "        except:\n",
        "            return -1\n",
        "\n",
        "    ans['prediction'] = ans['llm_output'].map(lambda x: process(x))\n",
        "    print(ans[ans.prediction == -1][['llm_output']], '\\n')\n",
        "\n",
        "    ans = ans[ans.prediction != -1]\n",
        "\n",
        "    rmse = mean_squared_error(ans['target'].tolist(), ans['prediction'].tolist(), squared = False)\n",
        "    mae = mean_absolute_error(ans['target'].tolist(), ans['prediction'].tolist())\n",
        "\n",
        "    print('MAE  = ', mae)\n",
        "    print('RMSE = ', rmse, '\\n')\n",
        "\n",
        "    return mae, rmse"
      ],
      "metadata": {
        "id": "kc61OoMjLHCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae, rmse = compute(['output.csv'], df)"
      ],
      "metadata": {
        "id": "sd_jxZ_3ShJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}